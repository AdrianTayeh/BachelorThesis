{
    "name": "root",
    "gauges": {
        "ZombieWalker.Policy.Entropy.mean": {
            "value": 1.5302144289016724,
            "min": 1.30458402633667,
            "max": 1.5302144289016724,
            "count": 100
        },
        "ZombieWalker.Policy.Entropy.sum": {
            "value": 15993.80078125,
            "min": 12655.513671875,
            "max": 16412.57421875,
            "count": 100
        },
        "ZombieWalker.Step.mean": {
            "value": 999977.0,
            "min": 9984.0,
            "max": 999977.0,
            "count": 100
        },
        "ZombieWalker.Step.sum": {
            "value": 999977.0,
            "min": 9984.0,
            "max": 999977.0,
            "count": 100
        },
        "ZombieWalker.Policy.ExtrinsicValueEstimate.mean": {
            "value": -85.4322738647461,
            "min": -36960.10546875,
            "max": 226780.34375,
            "count": 100
        },
        "ZombieWalker.Policy.ExtrinsicValueEstimate.sum": {
            "value": -13754.5966796875,
            "min": -5913617.0,
            "max": 36284856.0,
            "count": 100
        },
        "ZombieWalker.Losses.PolicyLoss.mean": {
            "value": 0.35956677319324953,
            "min": 0.22872557984053302,
            "max": 0.38509397249454336,
            "count": 100
        },
        "ZombieWalker.Losses.PolicyLoss.sum": {
            "value": 9.708302876217738,
            "min": 3.1137543011726327,
            "max": 17.409473259123594,
            "count": 100
        },
        "ZombieWalker.Losses.ValueLoss.mean": {
            "value": 49909466.362437375,
            "min": 0.0006569172334010303,
            "max": 185121078841446.72,
            "count": 100
        },
        "ZombieWalker.Losses.ValueLoss.sum": {
            "value": 1347555591.785809,
            "min": 0.01235668635774202,
            "max": 4998269128719061.0,
            "count": 100
        },
        "ZombieWalker.Policy.LearningRate.mean": {
            "value": 1.5203328265888875e-06,
            "min": 1.5203328265888875e-06,
            "max": 0.0002983872005376,
            "count": 100
        },
        "ZombieWalker.Policy.LearningRate.sum": {
            "value": 4.1048986317899964e-05,
            "min": 4.1048986317899964e-05,
            "max": 0.011583725738759,
            "count": 100
        },
        "ZombieWalker.Policy.Epsilon.mean": {
            "value": 0.1,
            "min": 0.09999999999999996,
            "max": 0.10000000000000003,
            "count": 100
        },
        "ZombieWalker.Policy.Epsilon.sum": {
            "value": 2.7,
            "min": 1.3000000000000003,
            "max": 6.699999999999999,
            "count": 100
        },
        "ZombieWalker.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005,
            "max": 0.0005000000000000003,
            "count": 100
        },
        "ZombieWalker.Policy.Beta.sum": {
            "value": 0.013500000000000003,
            "min": 0.006500000000000004,
            "max": 0.0335,
            "count": 100
        },
        "ZombieWalker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "ZombieWalker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "ZombieWalker.Environment.EpisodeLength.mean": {
            "value": 999.0,
            "min": 742.1428571428571,
            "max": 999.0,
            "count": 92
        },
        "ZombieWalker.Environment.EpisodeLength.sum": {
            "value": 11988.0,
            "min": 999.0,
            "max": 13327.0,
            "count": 92
        },
        "ZombieWalker.Environment.CumulativeReward.mean": {
            "value": 0.0,
            "min": -0.4,
            "max": 1.0,
            "count": 99
        },
        "ZombieWalker.Environment.CumulativeReward.sum": {
            "value": 0.0,
            "min": -4.0,
            "max": 8.0,
            "count": 99
        },
        "ZombieWalker.Policy.ExtrinsicReward.mean": {
            "value": 0.0,
            "min": -0.4,
            "max": 1.0,
            "count": 99
        },
        "ZombieWalker.Policy.ExtrinsicReward.sum": {
            "value": 0.0,
            "min": -4.0,
            "max": 8.0,
            "count": 99
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1711392794",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\01add\\Documents\\GitHub\\BachelorThesis\\venv\\Scripts\\mlagents-learn config/ZombieWalker.yaml --run-id=AdrianColTest18",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.0+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1711396356"
    },
    "total": 3561.6473143999997,
    "count": 1,
    "self": 0.011130299999422277,
    "children": {
        "run_training.setup": {
            "total": 0.10809500000000005,
            "count": 1,
            "self": 0.10809500000000005
        },
        "TrainerController.start_learning": {
            "total": 3561.5280891,
            "count": 1,
            "self": 1.6411213999895153,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.0983695,
                    "count": 1,
                    "self": 10.0983695
                },
                "TrainerController.advance": {
                    "total": 3549.734474600011,
                    "count": 83600,
                    "self": 1.7387937001103637,
                    "children": {
                        "env_step": {
                            "total": 1014.1832773999471,
                            "count": 83600,
                            "self": 927.1670778999411,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 85.96376880003233,
                                    "count": 83600,
                                    "self": 5.3729472000254646,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 80.59082160000686,
                                            "count": 83384,
                                            "self": 80.59082160000686
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.0524306999736552,
                                    "count": 83600,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3550.1481137999835,
                                            "count": 83600,
                                            "is_parallel": true,
                                            "self": 2724.4482777999747,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.000894199999999401,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00015280000000039706,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.000741399999999004,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.000741399999999004
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 825.6989418000087,
                                                    "count": 83600,
                                                    "is_parallel": true,
                                                    "self": 15.393534200027943,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 25.943011000048124,
                                                            "count": 83600,
                                                            "is_parallel": true,
                                                            "self": 25.943011000048124
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 745.5066956000005,
                                                            "count": 83600,
                                                            "is_parallel": true,
                                                            "self": 745.5066956000005
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 38.85570099993211,
                                                            "count": 83600,
                                                            "is_parallel": true,
                                                            "self": 8.498262499900182,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 30.35743850003193,
                                                                    "count": 167200,
                                                                    "is_parallel": true,
                                                                    "self": 30.35743850003193
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 2533.8124034999532,
                            "count": 83600,
                            "self": 2.310997299999144,
                            "children": {
                                "process_trajectory": {
                                    "total": 64.44898379995638,
                                    "count": 83600,
                                    "self": 64.30673589995612,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.14224790000025678,
                                            "count": 2,
                                            "self": 0.14224790000025678
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 2467.052422399998,
                                    "count": 3496,
                                    "self": 161.29257800016376,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 2305.759844399834,
                                            "count": 294522,
                                            "self": 2305.759844399834
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.000001798791345e-07,
                    "count": 1,
                    "self": 8.000001798791345e-07
                },
                "TrainerController._save_models": {
                    "total": 0.0541227999997318,
                    "count": 1,
                    "self": 0.01373299999977462,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.04038979999995718,
                            "count": 1,
                            "self": 0.04038979999995718
                        }
                    }
                }
            }
        }
    }
}